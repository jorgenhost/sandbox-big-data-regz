---
title: "R Notebook"
output: html_notebook
---


```{r}
install.packages("DBI")
install.packages("duckdb")
install.packages("modelsummary")
install.packages("Formula")
install.packages('packages/dbreg_0.0.2.99.tar.gz', repos = NULL, type='source')
```

```{r}
con = duckdb::dbConnect(duckdb::duckdb(), dbdir = "nyc-taxi/databaz.db")
DBI::dbExecute(con, "SET threads to 2;") # set no of threads as you see fit
```


```{r}
# Load packages after setting env vars
library(DBI)
library(duckdb)

library(dbreg)
library(modelsummary)
```



```{r}

dbExecute(con, "DROP TABLE IF EXISTS taxi;")
# create a 'taxi' table in our new nyc.db database from our parquet dataset
dbExecute(
    con,
    "
    CREATE OR REPLACE VIEW taxi AS
      SELECT *
      FROM read_parquet('nyc-taxi/**/*.pq')
    "
)
```

```{r}
# now run our regression against this conn+table combo
dbreg(
   tip_amount ~ fare_amount + passenger_count | week_x_weekday + month + VendorID,
   conn = con,     # database connection,
   table = "taxi", # table name
   vcov = "hc1"
)
```



```{r}
res = dbreg(tip_amount ~ fare_amount + passenger_count | week_x_weekday + month + VendorID,
   path = "read_parquet('nyc-taxi/**/*.pq')", ## path to hive-partitioned dataset
   vcov = "hc1")
saveRDS(res, "model.rds")
```
```{r}
res = dbreg(tip_amount ~ fare_amount + passenger_count | month + weekday,
   path = "read_parquet('temp.pq')", ## path to hive-partitioned dataset
   vcov = "hc1")
saveRDS(res, "modeltemp.rds")
res$coeftable
```

```{r}
res = readRDS("model.rds")

# We are interested in the full coeftable
res$coeftable
```

```{r}
con <- dbConnect(duckdb::duckdb(), dbdir = ":memory:")
# Describe the columns and types of the parquet table (read_parquet is a table function)
DBI::dbGetQuery(con, "DESCRIBE SELECT * FROM read_parquet('temp.pq')")
```

